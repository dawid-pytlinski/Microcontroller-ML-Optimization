{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, KLDivergence\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "teacher_model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "teacher_model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "teacher_model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "soft_targets = tf.nn.softmax(teacher_model.predict(X_train) / 3.0)\n",
    "soft_targets = tf.cast(soft_targets, tf.float32)\n",
    "\n",
    "def distillation_loss(y_true, y_pred):\n",
    "    alpha = 0.3\n",
    "    temperature = 3.0\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    batch_size = tf.shape(y_true)[0]\n",
    "\n",
    "    batch_soft_targets = tf.gather(soft_targets, tf.range(batch_size))\n",
    "\n",
    "    return alpha * SparseCategoricalCrossentropy()(y_true, y_pred) + \\\n",
    "           (1 - alpha) * KLDivergence()(batch_soft_targets, tf.nn.softmax(y_pred / temperature))\n",
    "\n",
    "student_model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "student_model.compile(optimizer=Adam(), loss=distillation_loss, metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "student_model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)\n",
    "student_training_time = time.time() - start_time\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, name):\n",
    "    start_time = time.time()\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "    inference_time = time.time() - start_time\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{name} Inference Time: {inference_time:.2f} s\")\n",
    "    print(f\"{name} Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    return inference_time\n",
    "\n",
    "teacher_inference_time = evaluate_model(teacher_model, X_test, y_test, \"Teacher Model\")\n",
    "student_inference_time = evaluate_model(student_model, X_test, y_test, \"Student Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, KLDivergence\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "teacher_model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "teacher_model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "teacher_model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "soft_targets = tf.nn.softmax(teacher_model.predict(X_train) / 3.0)\n",
    "soft_targets = tf.cast(soft_targets, tf.float32)\n",
    "\n",
    "def distillation_loss(y_true, y_pred):\n",
    "    alpha = 0.3\n",
    "    temperature = 3.0\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    batch_size = tf.shape(y_true)[0]\n",
    "    batch_soft_targets = tf.gather(soft_targets, tf.range(batch_size))\n",
    "\n",
    "    return alpha * SparseCategoricalCrossentropy()(y_true, y_pred) + \\\n",
    "           (1 - alpha) * KLDivergence()(batch_soft_targets, tf.nn.softmax(y_pred / temperature))\n",
    "\n",
    "student_model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "student_model.compile(optimizer=Adam(), loss=distillation_loss, metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "student_model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)\n",
    "student_training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Student Training Time: {student_training_time:.2f} s\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(student_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "with open(\"student_model_quantized.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_quantized_model)\n",
    "\n",
    "print(\"Quantized Student Model converted to TensorFlow Lite and saved as student_model_quantized.tflite\")\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, name):\n",
    "    start_time = time.time()\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "    inference_time = time.time() - start_time\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{name} Inference Time: {inference_time:.2f} s\")\n",
    "    print(f\"{name} Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    return inference_time\n",
    "\n",
    "teacher_inference_time = evaluate_model(teacher_model, X_test, y_test, \"Teacher Model\")\n",
    "student_inference_time = evaluate_model(student_model, X_test, y_test, \"Student Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
